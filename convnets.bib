
@book{alembertRecherchesDifferensPoints1754,
  title = {Recherches Sur Diff\'erens Points Importans Du Syst\`eme Du Monde, Par {{M}}. d'{{Alembert}}...},
  author = {d'{\aftergroup\ignorespaces} Alembert, Jean Le Rond and {undefined}},
  year = {1754},
  file = {/Users/lss/Zotero/storage/579QCGWN/001785020.html}
}

@article{dumoulinGuideConvolutionArithmetic2018,
  title = {A Guide to Convolution Arithmetic for Deep Learning},
  author = {Dumoulin, Vincent and Visin, Francesco},
  year = {2018},
  month = jan,
  journal = {arXiv:1603.07285 [cs, stat]},
  eprint = {1603.07285},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/lss/Zotero/storage/JC72X8W4/Dumoulin and Visin - 2018 - A guide to convolution arithmetic for deep learnin.pdf;/Users/lss/Zotero/storage/QGCDUSLT/1603.html}
}

@article{hubelEvolutionIdeasPrimary1982,
  title = {Evolution of Ideas on the Primary Visual Cortex, 1955\textendash 1978: {{A}} Biased Historical Account},
  shorttitle = {Evolution of Ideas on the Primary Visual Cortex, 1955\textendash 1978},
  author = {Hubel, David H.},
  year = {1982},
  month = jul,
  journal = {Bioscience Reports},
  volume = {2},
  number = {7},
  pages = {435--469},
  issn = {0144-8463, 1573-4935},
  doi = {10.1007/BF01115245},
  langid = {english},
  file = {/Users/lss/Zotero/storage/HCVBNZ77/Hubel - 1982 - Evolution of ideas on the primary visual cortex, 1.pdf}
}

@article{kwon_revacnn_2016,
  title = {Revacnn: {{Real-Time}} Visual Analytics for Convolutional Neural Network},
  author = {Chung, Sunghyo and Suh, Sangho and Park, Cheonbok and Kang, Kyeongpil and Choo, Jaegul and Kwon, Bum Chul},
  year = {2016},
  journal = {ACM SIGKDD workshop on interactive data exploration and analytics (IDEA)},
  file = {/Users/lss/Zotero/storage/Z2EIRUL9/revacnn.pdf}
}

@article{learned-millerVectorMatrixTensor,
  title = {Vector, {{Matrix}}, and {{Tensor Derivatives}}},
  author = {{Learned-Miller}, Erik},
  pages = {7},
  langid = {english},
  file = {/Users/lss/Zotero/storage/83Q65VY4/Learned-Miller - Vector, Matrix, and Tensor Derivatives.pdf}
}

@article{springenbergStrivingSimplicityAll2015,
  title = {Striving for {{Simplicity}}: {{The All Convolutional Net}}},
  shorttitle = {Striving for {{Simplicity}}},
  author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
  year = {2015},
  month = apr,
  journal = {arXiv:1412.6806 [cs]},
  eprint = {1412.6806},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  note = {Comment: accepted to ICLR-2015 workshop track; no changes other than style},
  file = {/Users/lss/Zotero/storage/C29H6VPL/Springenberg et al. - 2015 - Striving for Simplicity The All Convolutional Net.pdf;/Users/lss/Zotero/storage/4H84TKMQ/1412.html}
}

@article{yosinskiUnderstandingNeuralNetworks2015,
  title = {Understanding {{Neural Networks Through Deep Visualization}}},
  author = {Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
  year = {2015},
  month = jun,
  journal = {arXiv:1506.06579 [cs]},
  eprint = {1506.06579},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind. Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets. We introduce two such tools here. The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream). We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work. The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space. Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations. Both tools are open source and work on a pre-trained convnet with minimal setup.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  note = {Comment: 12 pages. To appear at ICML Deep Learning Workshop 2015},
  file = {/Users/lss/Zotero/storage/9CF2YKWU/Yosinski et al. - 2015 - Understanding Neural Networks Through Deep Visuali.pdf;/Users/lss/Zotero/storage/YIGMYUF5/1506.html}
}

@article{zeilerVisualizingUnderstandingConvolutional2013,
  title = {Visualizing and {{Understanding Convolutional Networks}}},
  author = {Zeiler, Matthew D. and Fergus, Rob},
  year = {2013},
  month = nov,
  journal = {arXiv:1311.2901 [cs]},
  eprint = {1311.2901},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky \textbackslash etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/lss/Zotero/storage/P7SQPV8L/Zeiler and Fergus - 2013 - Visualizing and Understanding Convolutional Networ.pdf;/Users/lss/Zotero/storage/KC9VQHYN/1311.html}
}


